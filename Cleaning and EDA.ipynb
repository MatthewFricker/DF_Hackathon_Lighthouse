{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assets.csv\")\n",
    "df = df[df[\"type\"] == \"model\"]\n",
    "#df.drop(columns=[\"sample\", \"datasheet\", \"included\", \"excluded\", \"adaptation\", \"output_space\", \"terms_of_service\", \"monthly_active_users\", \"user_distribution\", \"failures\"], inplace=True)\n",
    "df[\"created_date\"] = pd.to_datetime(df[\"created_date\"], format=\"%d/%m/%Y\")\n",
    "df[\"inputs\"] = df.modality.str.split(\"; \").str[0].str.split(\", \")\n",
    "df[\"outputs\"] = df.modality.str.split(\"; \").str[1].str.split(\", \")\n",
    "df.drop(columns=\"modality\", inplace = True)\n",
    "df[\"size\"] = df[\"size\"].apply(lambda x: np.nan if x == \"unknown\" else x)\n",
    "df[\"dense\"] = df[\"size\"].str.endswith(\"(dense)\")\n",
    "df[\"dense\"].fillna(False, inplace=True)\n",
    "df[\"parameters\"] = df[\"size\"].str.extract(r\"^(\\d+[a-zA-Z])\")\n",
    "df[\"parameters_(millions)\"] = df[\"parameters\"].str.replace(\"M\", \"\").str.replace(\"B\", \"000\").str.replace(\"T\", \"000000\")\n",
    "df[\"parameters_(millions)\"] = pd.to_numeric(df[\"parameters_(millions)\"], downcast=\"integer\")\n",
    "df.drop(columns=[\"size\", \"parameters\"], inplace=True)\n",
    "df[\"dependencies\"] = df[\"dependencies\"].apply(lambda x: x[1:-1].split(','))\n",
    "df[\"analysis\"].fillna(\"unknown\", inplace=True)\n",
    "df[\"access\"] = df[\"access\"].map({\"open\":2, \"limited\":1, \"closed\": 0})\n",
    "df[\"training_time\"].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 359 entries, 3 to 564\n",
      "Data columns (total 33 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   type                   359 non-null    object        \n",
      " 1   name                   359 non-null    object        \n",
      " 2   organization           359 non-null    object        \n",
      " 3   description            299 non-null    object        \n",
      " 4   created_date           357 non-null    datetime64[ns]\n",
      " 5   url                    357 non-null    object        \n",
      " 6   datasheet              0 non-null      object        \n",
      " 7   sample                 0 non-null      object        \n",
      " 8   analysis               359 non-null    object        \n",
      " 9   dependencies           359 non-null    object        \n",
      " 10  included               0 non-null      object        \n",
      " 11  excluded               0 non-null      object        \n",
      " 12  quality_control        85 non-null     object        \n",
      " 13  access                 359 non-null    int64         \n",
      " 14  license                343 non-null    object        \n",
      " 15  intended_uses          129 non-null    object        \n",
      " 16  prohibited_uses        86 non-null     object        \n",
      " 17  monitoring             118 non-null    object        \n",
      " 18  feedback               161 non-null    object        \n",
      " 19  model_card             170 non-null    object        \n",
      " 20  training_emissions     244 non-null    object        \n",
      " 21  training_time          359 non-null    object        \n",
      " 22  training_hardware      262 non-null    object        \n",
      " 23  adaptation             0 non-null      object        \n",
      " 24  output_space           0 non-null      object        \n",
      " 25  terms_of_service       0 non-null      object        \n",
      " 26  monthly_active_users   0 non-null      object        \n",
      " 27  user_distribution      0 non-null      object        \n",
      " 28  failures               0 non-null      object        \n",
      " 29  inputs                 357 non-null    object        \n",
      " 30  outputs                349 non-null    object        \n",
      " 31  dense                  359 non-null    bool          \n",
      " 32  parameters_(millions)  241 non-null    float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int64(1), object(29)\n",
      "memory usage: 92.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>organization</th>\n",
       "      <th>description</th>\n",
       "      <th>created_date</th>\n",
       "      <th>url</th>\n",
       "      <th>datasheet</th>\n",
       "      <th>sample</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>included</th>\n",
       "      <th>excluded</th>\n",
       "      <th>quality_control</th>\n",
       "      <th>access</th>\n",
       "      <th>license</th>\n",
       "      <th>intended_uses</th>\n",
       "      <th>prohibited_uses</th>\n",
       "      <th>monitoring</th>\n",
       "      <th>feedback</th>\n",
       "      <th>model_card</th>\n",
       "      <th>training_emissions</th>\n",
       "      <th>training_time</th>\n",
       "      <th>training_hardware</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>output_space</th>\n",
       "      <th>terms_of_service</th>\n",
       "      <th>monthly_active_users</th>\n",
       "      <th>user_distribution</th>\n",
       "      <th>failures</th>\n",
       "      <th>inputs</th>\n",
       "      <th>outputs</th>\n",
       "      <th>dense</th>\n",
       "      <th>parameters_(millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>model</td>\n",
       "      <td>BioMistral</td>\n",
       "      <td>Avignon University, Nantes University</td>\n",
       "      <td>BioMistral is an open-source Large Language Mo...</td>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>https://arxiv.org/pdf/2402.10373.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BioMistral was evaluated on a benchmark compri...</td>\n",
       "      <td>['Mistral',  'PubMed Central']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Apache 2.0</td>\n",
       "      <td>Research in the biomedical domain, especially ...</td>\n",
       "      <td>Prohibited from deploying in production enviro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/BioMistral/BioMistral-7...</td>\n",
       "      <td>https://huggingface.co/BioMistral/BioMistral-7B</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>32 NVIDIA A100 80GB GPUs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>True</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>model</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Mistral is a compact language model.</td>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>https://mistral.ai/news/announcing-mistral-7b/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evaluated in comparison to LLaMA series models...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Apache 2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/mistralai/Mistral-7B-v0...</td>\n",
       "      <td>https://huggingface.co/mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>model</td>\n",
       "      <td>Mistral Large</td>\n",
       "      <td>Mistral AI</td>\n",
       "      <td>Mistral Large is Mistral AI’s new cutting-edge...</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>https://mistral.ai/news/mistral-large/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evaluated on commonly used benchmarks in compa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>model</td>\n",
       "      <td>YaRN Mistral</td>\n",
       "      <td>Nous Research, EleutherAI, University of Geneva</td>\n",
       "      <td>YaRN Mistral is an adapted version of Mistral ...</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>https://arxiv.org/pdf/2309.00071.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evaluated across a variety of standard benchma...</td>\n",
       "      <td>['Mistral']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>MIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://huggingface.co/NousResearch/Yarn-Mistr...</td>\n",
       "      <td>https://huggingface.co/NousResearch/Yarn-Mistr...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>True</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>model</td>\n",
       "      <td>OpenHermes 2.5 Mistral</td>\n",
       "      <td>Nous Research</td>\n",
       "      <td>OpenHermes 2.5 Mistral 7B is a state of the ar...</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>https://huggingface.co/teknium/OpenHermes-2.5-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evaluated on common LLM benchmarks in comparis...</td>\n",
       "      <td>['Mistral']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Apache 2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://huggingface.co/teknium/OpenHermes-2.5-...</td>\n",
       "      <td>https://huggingface.co/teknium/OpenHermes-2.5-...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>True</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>model</td>\n",
       "      <td>Hermes 2 Pro-Mistral</td>\n",
       "      <td>Nous</td>\n",
       "      <td>Hermes 2 Pro on Mistral 7B is an upgraded, ret...</td>\n",
       "      <td>2024-03-10</td>\n",
       "      <td>https://huggingface.co/NousResearch/Hermes-2-P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The model was examined across a range of bench...</td>\n",
       "      <td>['Mistral',  'OpenHermes 2.5 Dataset',  'Nous ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The model was evaluated across multiple tasks,...</td>\n",
       "      <td>2</td>\n",
       "      <td>Apache 2.0</td>\n",
       "      <td>The model is intended for general task and con...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://huggingface.co/NousResearch/Hermes-2-P...</td>\n",
       "      <td>https://huggingface.co/NousResearch/Hermes-2-P...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>True</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>model</td>\n",
       "      <td>SciPhi Mistral</td>\n",
       "      <td>SciPhi</td>\n",
       "      <td>SciPhi Mistral is a Large Language Model (LLM)...</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>https://huggingface.co/SciPhi/SciPhi-Mistral-7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>['Mistral']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>MIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://huggingface.co/SciPhi/SciPhi-Mistral-7...</td>\n",
       "      <td>https://huggingface.co/SciPhi/SciPhi-Mistral-7...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>True</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                    name  \\\n",
       "34   model              BioMistral   \n",
       "64   model                 Mistral   \n",
       "65   model           Mistral Large   \n",
       "520  model            YaRN Mistral   \n",
       "521  model  OpenHermes 2.5 Mistral   \n",
       "522  model    Hermes 2 Pro-Mistral   \n",
       "561  model          SciPhi Mistral   \n",
       "\n",
       "                                        organization  \\\n",
       "34             Avignon University, Nantes University   \n",
       "64                                        Mistral AI   \n",
       "65                                        Mistral AI   \n",
       "520  Nous Research, EleutherAI, University of Geneva   \n",
       "521                                    Nous Research   \n",
       "522                                             Nous   \n",
       "561                                           SciPhi   \n",
       "\n",
       "                                           description created_date  \\\n",
       "34   BioMistral is an open-source Large Language Mo...   2024-02-15   \n",
       "64                Mistral is a compact language model.   2023-09-27   \n",
       "65   Mistral Large is Mistral AI’s new cutting-edge...   2024-02-26   \n",
       "520  YaRN Mistral is an adapted version of Mistral ...   2023-11-01   \n",
       "521  OpenHermes 2.5 Mistral 7B is a state of the ar...   2023-11-03   \n",
       "522  Hermes 2 Pro on Mistral 7B is an upgraded, ret...   2024-03-10   \n",
       "561  SciPhi Mistral is a Large Language Model (LLM)...   2023-11-07   \n",
       "\n",
       "                                                   url datasheet sample  \\\n",
       "34                https://arxiv.org/pdf/2402.10373.pdf       NaN    NaN   \n",
       "64      https://mistral.ai/news/announcing-mistral-7b/       NaN    NaN   \n",
       "65              https://mistral.ai/news/mistral-large/       NaN    NaN   \n",
       "520               https://arxiv.org/pdf/2309.00071.pdf       NaN    NaN   \n",
       "521  https://huggingface.co/teknium/OpenHermes-2.5-...       NaN    NaN   \n",
       "522  https://huggingface.co/NousResearch/Hermes-2-P...       NaN    NaN   \n",
       "561  https://huggingface.co/SciPhi/SciPhi-Mistral-7...       NaN    NaN   \n",
       "\n",
       "                                              analysis  \\\n",
       "34   BioMistral was evaluated on a benchmark compri...   \n",
       "64   Evaluated in comparison to LLaMA series models...   \n",
       "65   Evaluated on commonly used benchmarks in compa...   \n",
       "520  Evaluated across a variety of standard benchma...   \n",
       "521  Evaluated on common LLM benchmarks in comparis...   \n",
       "522  The model was examined across a range of bench...   \n",
       "561                                            unknown   \n",
       "\n",
       "                                          dependencies included excluded  \\\n",
       "34                      ['Mistral',  'PubMed Central']      NaN      NaN   \n",
       "64                                                  []      NaN      NaN   \n",
       "65                                                  []      NaN      NaN   \n",
       "520                                        ['Mistral']      NaN      NaN   \n",
       "521                                        ['Mistral']      NaN      NaN   \n",
       "522  ['Mistral',  'OpenHermes 2.5 Dataset',  'Nous ...      NaN      NaN   \n",
       "561                                        ['Mistral']      NaN      NaN   \n",
       "\n",
       "                                       quality_control  access     license  \\\n",
       "34                                                 NaN       2  Apache 2.0   \n",
       "64                                                 NaN       2  Apache 2.0   \n",
       "65                                                 NaN       1     unknown   \n",
       "520                                                NaN       2         MIT   \n",
       "521                                                NaN       2  Apache 2.0   \n",
       "522  The model was evaluated across multiple tasks,...       2  Apache 2.0   \n",
       "561                                                NaN       2         MIT   \n",
       "\n",
       "                                         intended_uses  \\\n",
       "34   Research in the biomedical domain, especially ...   \n",
       "64                                                 NaN   \n",
       "65                                                 NaN   \n",
       "520                                                NaN   \n",
       "521                                                NaN   \n",
       "522  The model is intended for general task and con...   \n",
       "561                                                NaN   \n",
       "\n",
       "                                       prohibited_uses monitoring  \\\n",
       "34   Prohibited from deploying in production enviro...        NaN   \n",
       "64                                                 NaN        NaN   \n",
       "65                                                 NaN        NaN   \n",
       "520                                                NaN    unknown   \n",
       "521                                                NaN    unknown   \n",
       "522                                            unknown    unknown   \n",
       "561                                                NaN    unknown   \n",
       "\n",
       "                                              feedback  \\\n",
       "34   https://huggingface.co/BioMistral/BioMistral-7...   \n",
       "64   https://huggingface.co/mistralai/Mistral-7B-v0...   \n",
       "65                                                 NaN   \n",
       "520  https://huggingface.co/NousResearch/Yarn-Mistr...   \n",
       "521  https://huggingface.co/teknium/OpenHermes-2.5-...   \n",
       "522  https://huggingface.co/NousResearch/Hermes-2-P...   \n",
       "561  https://huggingface.co/SciPhi/SciPhi-Mistral-7...   \n",
       "\n",
       "                                            model_card training_emissions  \\\n",
       "34     https://huggingface.co/BioMistral/BioMistral-7B            unknown   \n",
       "64    https://huggingface.co/mistralai/Mistral-7B-v0.1            unknown   \n",
       "65                                                 NaN            unknown   \n",
       "520  https://huggingface.co/NousResearch/Yarn-Mistr...            unknown   \n",
       "521  https://huggingface.co/teknium/OpenHermes-2.5-...            unknown   \n",
       "522  https://huggingface.co/NousResearch/Hermes-2-P...            unknown   \n",
       "561  https://huggingface.co/SciPhi/SciPhi-Mistral-7...            unknown   \n",
       "\n",
       "    training_time         training_hardware adaptation output_space  \\\n",
       "34        unknown  32 NVIDIA A100 80GB GPUs        NaN          NaN   \n",
       "64        unknown                   unknown        NaN          NaN   \n",
       "65        unknown                   unknown        NaN          NaN   \n",
       "520       unknown                   unknown        NaN          NaN   \n",
       "521       unknown                   unknown        NaN          NaN   \n",
       "522       unknown                   unknown        NaN          NaN   \n",
       "561       unknown                   unknown        NaN          NaN   \n",
       "\n",
       "    terms_of_service monthly_active_users user_distribution failures  inputs  \\\n",
       "34               NaN                  NaN               NaN      NaN  [text]   \n",
       "64               NaN                  NaN               NaN      NaN  [text]   \n",
       "65               NaN                  NaN               NaN      NaN  [text]   \n",
       "520              NaN                  NaN               NaN      NaN  [text]   \n",
       "521              NaN                  NaN               NaN      NaN  [text]   \n",
       "522              NaN                  NaN               NaN      NaN  [text]   \n",
       "561              NaN                  NaN               NaN      NaN  [text]   \n",
       "\n",
       "    outputs  dense  parameters_(millions)  \n",
       "34   [text]   True                 7000.0  \n",
       "64   [text]   True                    NaN  \n",
       "65   [text]  False                    NaN  \n",
       "520  [text]   True                 7000.0  \n",
       "521  [text]   True                 7000.0  \n",
       "522  [text]   True                 7000.0  \n",
       "561  [text]   True                 7000.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"name\"].str.contains(\"Mistral\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>organization</th>\n",
       "      <th>description</th>\n",
       "      <th>created_date</th>\n",
       "      <th>url</th>\n",
       "      <th>datasheet</th>\n",
       "      <th>sample</th>\n",
       "      <th>analysis</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>included</th>\n",
       "      <th>excluded</th>\n",
       "      <th>quality_control</th>\n",
       "      <th>access</th>\n",
       "      <th>license</th>\n",
       "      <th>intended_uses</th>\n",
       "      <th>prohibited_uses</th>\n",
       "      <th>monitoring</th>\n",
       "      <th>feedback</th>\n",
       "      <th>model_card</th>\n",
       "      <th>training_emissions</th>\n",
       "      <th>training_time</th>\n",
       "      <th>training_hardware</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>output_space</th>\n",
       "      <th>terms_of_service</th>\n",
       "      <th>monthly_active_users</th>\n",
       "      <th>user_distribution</th>\n",
       "      <th>failures</th>\n",
       "      <th>inputs</th>\n",
       "      <th>outputs</th>\n",
       "      <th>dense</th>\n",
       "      <th>parameters_(millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>model</td>\n",
       "      <td>Vicuna</td>\n",
       "      <td>LMSYS</td>\n",
       "      <td>An open-source chatbot trained by fine-tuning ...</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>https://lmsys.org/blog/2023-03-30-vicuna/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evaluated against similar LLMs using GPT-4 as ...</td>\n",
       "      <td>['LLaMA',  'ShareGPT conversations data']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Apache 2.0</td>\n",
       "      <td>research on LLMs and chatbots</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/datasets/bigcode/the-st...</td>\n",
       "      <td>https://huggingface.co/lmsys/vicuna-13b-delta-v0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 day</td>\n",
       "      <td>8 A100 GPUs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[text]</td>\n",
       "      <td>[text]</td>\n",
       "      <td>True</td>\n",
       "      <td>13000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type    name organization  \\\n",
       "428  model  Vicuna        LMSYS   \n",
       "\n",
       "                                           description created_date  \\\n",
       "428  An open-source chatbot trained by fine-tuning ...   2023-03-30   \n",
       "\n",
       "                                           url datasheet sample  \\\n",
       "428  https://lmsys.org/blog/2023-03-30-vicuna/       NaN    NaN   \n",
       "\n",
       "                                              analysis  \\\n",
       "428  Evaluated against similar LLMs using GPT-4 as ...   \n",
       "\n",
       "                                  dependencies included excluded  \\\n",
       "428  ['LLaMA',  'ShareGPT conversations data']      NaN      NaN   \n",
       "\n",
       "    quality_control  access     license                  intended_uses  \\\n",
       "428             NaN       2  Apache 2.0  research on LLMs and chatbots   \n",
       "\n",
       "    prohibited_uses monitoring  \\\n",
       "428             NaN        NaN   \n",
       "\n",
       "                                              feedback  \\\n",
       "428  https://huggingface.co/datasets/bigcode/the-st...   \n",
       "\n",
       "                                           model_card training_emissions  \\\n",
       "428  https://huggingface.co/lmsys/vicuna-13b-delta-v0                NaN   \n",
       "\n",
       "    training_time training_hardware adaptation output_space terms_of_service  \\\n",
       "428         1 day       8 A100 GPUs        NaN          NaN              NaN   \n",
       "\n",
       "    monthly_active_users user_distribution failures  inputs outputs  dense  \\\n",
       "428                  NaN               NaN      NaN  [text]  [text]   True   \n",
       "\n",
       "     parameters_(millions)  \n",
       "428                13000.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"name\"] == \"Vicuna\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
