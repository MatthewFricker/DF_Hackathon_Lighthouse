{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assets.csv\")\n",
    "df = df[df[\"type\"] == \"model\"]\n",
    "df.drop(columns=[\"sample\", \"datasheet\", \"included\", \"excluded\", \"adaptation\", \"output_space\", \"terms_of_service\", \"monthly_active_users\", \"user_distribution\", \"failures\"], inplace=True)\n",
    "df[\"created_date\"] = pd.to_datetime(df[\"created_date\"], format=\"%d/%m/%Y\")\n",
    "df[\"inputs\"] = df.modality.str.split(\"; \").str[0].str.split(\", \")\n",
    "df[\"outputs\"] = df.modality.str.split(\"; \").str[1].str.split(\", \")\n",
    "df.drop(columns=\"modality\", inplace = True)\n",
    "df[\"size\"] = df[\"size\"].apply(lambda x: np.nan if x == \"unknown\" else x)\n",
    "df[\"dense\"] = df[\"size\"].str.endswith(\"(dense)\")\n",
    "df[\"dense\"].fillna(False, inplace=True)\n",
    "df[\"parameters\"] = df[\"size\"].str.extract(r\"^(\\d+[a-zA-Z])\")\n",
    "df[\"parameters_(millions)\"] = df[\"parameters\"].str.replace(\"M\", \"\").str.replace(\"B\", \"000\").str.replace(\"T\", \"000000\")\n",
    "df[\"parameters_(millions)\"] = pd.to_numeric(df[\"parameters_(millions)\"], downcast=\"integer\")\n",
    "df.drop(columns=[\"size\", \"parameters\"], inplace=True)\n",
    "df[\"dependencies\"] = df[\"dependencies\"].apply(lambda x: x[1:-1].split(','))\n",
    "df[\"analysis\"].fillna(\"unknown\", inplace=True)\n",
    "df[\"access\"] = df[\"access\"].map({\"open\":2, \"limited\":1, \"closed\": 0})\n",
    "df[\"training_time\"].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 359 entries, 3 to 564\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   type                   359 non-null    object        \n",
      " 1   name                   359 non-null    object        \n",
      " 2   organization           359 non-null    object        \n",
      " 3   description            299 non-null    object        \n",
      " 4   created_date           357 non-null    datetime64[ns]\n",
      " 5   url                    357 non-null    object        \n",
      " 6   analysis               359 non-null    object        \n",
      " 7   dependencies           359 non-null    object        \n",
      " 8   quality_control        85 non-null     object        \n",
      " 9   access                 359 non-null    int64         \n",
      " 10  license                343 non-null    object        \n",
      " 11  intended_uses          129 non-null    object        \n",
      " 12  prohibited_uses        86 non-null     object        \n",
      " 13  monitoring             118 non-null    object        \n",
      " 14  feedback               161 non-null    object        \n",
      " 15  model_card             170 non-null    object        \n",
      " 16  training_emissions     244 non-null    object        \n",
      " 17  training_time          359 non-null    object        \n",
      " 18  training_hardware      262 non-null    object        \n",
      " 19  inputs                 357 non-null    object        \n",
      " 20  outputs                349 non-null    object        \n",
      " 21  dense                  359 non-null    bool          \n",
      " 22  parameters_(millions)  241 non-null    float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int64(1), object(19)\n",
      "memory usage: 64.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3                         A single NVIDIA Tesla-P100 GPU\n",
       "4                                                    NaN\n",
       "6                                                unknown\n",
       "7                                      2x A100 80GB GPUs\n",
       "11                                                   NaN\n",
       "                             ...                        \n",
       "559                                              unknown\n",
       "561                                              unknown\n",
       "562                                   8 x A100 40GB GPUs\n",
       "563    56 DGX A100 nodes, each equipped with 4 80GB A...\n",
       "564    Trained on the Cerebras Condor Galaxy 1 (CG-1)...\n",
       "Name: training_hardware, Length: 359, dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"training_hardware\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>organization</th>\n",
       "      <th>parameters_(millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Megatron-LM</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>Samba 1</td>\n",
       "      <td>Samba Nova Systems</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>PaLM-E</td>\n",
       "      <td>Google</td>\n",
       "      <td>562000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Med-PaLM Multimodal</td>\n",
       "      <td>Google</td>\n",
       "      <td>562000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>PaLM-SayCan</td>\n",
       "      <td>Google</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Minerva</td>\n",
       "      <td>Google</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>U-PaLM</td>\n",
       "      <td>Google</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Flan-U-PaLM</td>\n",
       "      <td>Google</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Flan-PaLM</td>\n",
       "      <td>Google</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Med-PaLM</td>\n",
       "      <td>Google</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>PaLM</td>\n",
       "      <td>Google</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Megatron-Turing NLG</td>\n",
       "      <td>Microsoft, NVIDIA</td>\n",
       "      <td>530000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Grok-1</td>\n",
       "      <td>xAI</td>\n",
       "      <td>314000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Gopher</td>\n",
       "      <td>Google Deepmind</td>\n",
       "      <td>280000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>GopherCite</td>\n",
       "      <td>Google Deepmind</td>\n",
       "      <td>280000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ERNIE 3.0 Titan</td>\n",
       "      <td>Baidu, PengCheng Laboratory</td>\n",
       "      <td>260000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Luminous</td>\n",
       "      <td>Aleph Alpha</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>TigerBot</td>\n",
       "      <td>TigerResearch</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Vulture</td>\n",
       "      <td>Virtual Interactive</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Falcon-180B</td>\n",
       "      <td>UAE Technology Innovation Institute</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Jurassic-1</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>178000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>BLOOM</td>\n",
       "      <td>BigScience</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>BLOOMZ</td>\n",
       "      <td>BigScience</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BLUUMI</td>\n",
       "      <td>University of Turku, HuggingFace, National Lib...</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>GPT-3</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>175000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>InstructGPT</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>175000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>OPT</td>\n",
       "      <td>Meta</td>\n",
       "      <td>175000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>OPT-IML</td>\n",
       "      <td>Meta</td>\n",
       "      <td>175000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>LaMDA</td>\n",
       "      <td>Google</td>\n",
       "      <td>137000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>DBRX</td>\n",
       "      <td>Databricks</td>\n",
       "      <td>132000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>GLM-130B</td>\n",
       "      <td>Tsinghua University</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Galactica</td>\n",
       "      <td>Meta</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>SaiLY</td>\n",
       "      <td>Deepnight Research</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>YaLM</td>\n",
       "      <td>Yandex</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>HyperCLOVA</td>\n",
       "      <td>NAVER</td>\n",
       "      <td>82000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Flamingo</td>\n",
       "      <td>Google Deepmind</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Pegasus-1</td>\n",
       "      <td>Twelve Labs</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>IDEFICS</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Qwen 1.5</td>\n",
       "      <td>Alibaba</td>\n",
       "      <td>72000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>MoMo</td>\n",
       "      <td>Moreh</td>\n",
       "      <td>72000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Chinchilla</td>\n",
       "      <td>Google Deepmind</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Xwin-LM</td>\n",
       "      <td>Xwin</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Tulu 2</td>\n",
       "      <td>AI2</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>YaRN LLaMA 2</td>\n",
       "      <td>Nous Research, EleutherAI, University of Geneva</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Eurus</td>\n",
       "      <td>OpenBMB</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>GodziLLa 2</td>\n",
       "      <td>Maya Philippines</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Dramatron</td>\n",
       "      <td>Google Deepmind</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Llama 2</td>\n",
       "      <td>Meta</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Llama 3</td>\n",
       "      <td>Meta</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Tulu 2 DPO</td>\n",
       "      <td>AI2</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                       organization  \\\n",
       "524          Megatron-LM                                             NVIDIA   \n",
       "559              Samba 1                                 Samba Nova Systems   \n",
       "202               PaLM-E                                             Google   \n",
       "163  Med-PaLM Multimodal                                             Google   \n",
       "169          PaLM-SayCan                                             Google   \n",
       "198              Minerva                                             Google   \n",
       "168               U-PaLM                                             Google   \n",
       "166          Flan-U-PaLM                                             Google   \n",
       "165            Flan-PaLM                                             Google   \n",
       "162             Med-PaLM                                             Google   \n",
       "160                 PaLM                                             Google   \n",
       "457  Megatron-Turing NLG                                  Microsoft, NVIDIA   \n",
       "507               Grok-1                                                xAI   \n",
       "291               Gopher                                    Google Deepmind   \n",
       "300           GopherCite                                    Google Deepmind   \n",
       "105      ERNIE 3.0 Titan                        Baidu, PengCheng Laboratory   \n",
       "545             Luminous                                        Aleph Alpha   \n",
       "491             TigerBot                                      TigerResearch   \n",
       "74               Vulture                                Virtual Interactive   \n",
       "445          Falcon-180B                UAE Technology Innovation Institute   \n",
       "341           Jurassic-1                                          AI21 Labs   \n",
       "417                BLOOM                                         BigScience   \n",
       "419               BLOOMZ                                         BigScience   \n",
       "45                BLUUMI  University of Turku, HuggingFace, National Lib...   \n",
       "239                GPT-3                                             OpenAI   \n",
       "241          InstructGPT                                             OpenAI   \n",
       "382                  OPT                                               Meta   \n",
       "387              OPT-IML                                               Meta   \n",
       "153                LaMDA                                             Google   \n",
       "427                 DBRX                                         Databricks   \n",
       "91              GLM-130B                                Tsinghua University   \n",
       "380            Galactica                                               Meta   \n",
       "436                SaiLY                                 Deepnight Research   \n",
       "531                 YaLM                                             Yandex   \n",
       "216           HyperCLOVA                                              NAVER   \n",
       "289             Flamingo                                    Google Deepmind   \n",
       "130            Pegasus-1                                        Twelve Labs   \n",
       "42               IDEFICS                                        HuggingFace   \n",
       "553             Qwen 1.5                                            Alibaba   \n",
       "63                  MoMo                                              Moreh   \n",
       "292           Chinchilla                                    Google Deepmind   \n",
       "358              Xwin-LM                                               Xwin   \n",
       "317               Tulu 2                                                AI2   \n",
       "518         YaRN LLaMA 2    Nous Research, EleutherAI, University of Geneva   \n",
       "374                Eurus                                            OpenBMB   \n",
       "132           GodziLLa 2                                   Maya Philippines   \n",
       "303            Dramatron                                    Google Deepmind   \n",
       "386              Llama 2                                               Meta   \n",
       "399              Llama 3                                               Meta   \n",
       "318           Tulu 2 DPO                                                AI2   \n",
       "\n",
       "     parameters_(millions)  \n",
       "524              1000000.0  \n",
       "559              1000000.0  \n",
       "202               562000.0  \n",
       "163               562000.0  \n",
       "169               540000.0  \n",
       "198               540000.0  \n",
       "168               540000.0  \n",
       "166               540000.0  \n",
       "165               540000.0  \n",
       "162               540000.0  \n",
       "160               540000.0  \n",
       "457               530000.0  \n",
       "507               314000.0  \n",
       "291               280000.0  \n",
       "300               280000.0  \n",
       "105               260000.0  \n",
       "545               200000.0  \n",
       "491               180000.0  \n",
       "74                180000.0  \n",
       "445               180000.0  \n",
       "341               178000.0  \n",
       "417               176000.0  \n",
       "419               176000.0  \n",
       "45                176000.0  \n",
       "239               175000.0  \n",
       "241               175000.0  \n",
       "382               175000.0  \n",
       "387               175000.0  \n",
       "153               137000.0  \n",
       "427               132000.0  \n",
       "91                130000.0  \n",
       "380               120000.0  \n",
       "436               100000.0  \n",
       "531               100000.0  \n",
       "216                82000.0  \n",
       "289                80000.0  \n",
       "130                80000.0  \n",
       "42                 80000.0  \n",
       "553                72000.0  \n",
       "63                 72000.0  \n",
       "292                70000.0  \n",
       "358                70000.0  \n",
       "317                70000.0  \n",
       "518                70000.0  \n",
       "374                70000.0  \n",
       "132                70000.0  \n",
       "303                70000.0  \n",
       "386                70000.0  \n",
       "399                70000.0  \n",
       "318                70000.0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"parameters_(millions)\", ascending=False)[[\"name\", \"organization\", \"parameters_(millions)\"]].head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
